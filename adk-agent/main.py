import os
import json

from openai import OpenAI
from openai.types.chat import ChatCompletionMessageParam, ChatCompletionToolParam
from dotenv import load_dotenv
from core.agent import BaseAgent
from core.utils import validate_openai_api_key

# .env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()


def calculate(expression: str) -> str:
    """ä¸ãˆã‚‰ã‚ŒãŸæ•°å¼ã‚’è¨ˆç®—ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€‚

    Python ã® eval é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€æ–‡å­—åˆ—ã¨ã—ã¦å—ã‘å–ã£ãŸæ•°å¼ã‚’ç›´æ¥è©•ä¾¡ï¼ˆè¨ˆç®—ï¼‰ã—ã¾ã™ã€‚
    ãƒ‡ãƒ¢ç›®çš„ã®ãŸã‚ã€__builtins__ ã‚’åˆ¶é™ã—ã¦å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

    Args:
        expression (str): è¨ˆç®—ã™ã‚‹æ•°å¼ (ä¾‹: "3 + 5")

    Returns:
        str: è¨ˆç®—çµæœã®æ–‡å­—åˆ—ã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    print(f"[Tool] Calculating: {expression}")
    try:
        # evalã¯å®‰å…¨ã§ã¯ãªã„ãŒã€ãƒ‡ãƒ¢ç›®çš„ã§åˆ¶é™ä»˜ãã§å®Ÿè¡Œ
        result = eval(expression, {"__builtins__": None}, {})
        return f"{result} ğŸš€"
    except Exception as e:
        return f"Error: {str(e)}"


# --- ADK Components ---


class Memory:
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨˜æ†¶ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚"""

    def __init__(self):
        self.messages: list[ChatCompletionMessageParam] = []

    def add_message(
        self,
        role: str,
        content: str,
        tool_calls: list[object] | None = None,
        tool_call_id: str | None = None,
        name: str | None = None,
    ):
        message: dict[str, object] = {"role": role, "content": content}
        if tool_calls:
            message["tool_calls"] = tool_calls
        if tool_call_id:
            message["tool_call_id"] = tool_call_id
        if name:
            message["name"] = name
        self.messages.append(message)  # type: ignore

    def get_messages(self) -> list[ChatCompletionMessageParam]:
        return self.messages


class Planner:
    """LLMã‚’ç”¨ã„ã¦æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ€è€ƒã¾ãŸã¯ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œï¼‰ã‚’æ±ºå®šã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚"""

    def __init__(self, client: OpenAI, model: str = "gpt-4o"):
        self.client = client
        self.model = model
        self.tools: list[ChatCompletionToolParam] = [
            {
                "type": "function",
                "function": {
                    "name": "calculate",
                    "description": "æ•°å¼ã‚’å—ã‘å–ã‚Šã€ãã®è¨ˆç®—çµæœã‚’è¿”ã™ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "expression": {
                                "type": "string",
                                "description": "è¨ˆç®—ã™ã‚‹æ•°å¼ (ä¾‹: '3 + 5')",
                            }
                        },
                        "required": ["expression"],
                    },
                },
            }
        ]

    def plan(self, memory: Memory) -> object:
        print("[Planner] Planning next step...")
        response = self.client.chat.completions.create(
            model=self.model,
            messages=memory.get_messages(),
            tools=self.tools,
            tool_choice="auto",
        )
        return response.choices[0].message


class Executor:
    """PlannerãŒæ±ºå®šã—ãŸãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚"""

    @staticmethod
    def execute(tool_call: object) -> str:
        # tool_call ã¯é€šå¸¸ ChatCompletionMessageToolCall ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        # å‹ãƒã‚§ãƒƒã‚¯ã‚’å›é¿ã—ã¤ã¤å±æ€§ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ getattr ç­‰ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€object ã¨ã—ã¦æ‰±ã†
        function_name = getattr(getattr(tool_call, "function", None), "name", None)
        function_args_str = getattr(
            getattr(tool_call, "function", None), "arguments", "{}"
        )
        function_args = json.loads(function_args_str)

        print(f"[Executor] Executing tool: {function_name} with args: {function_args}")

        if function_name == "calculate":
            return calculate(function_args.get("expression", ""))
        else:
            return f"Error: Unknown tool {function_name}"


class Agent(BaseAgent):
    """Planner, Executor, Memory ã‚’çµ±æ‹¬ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’åˆ¶å¾¡ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚"""

    def __init__(self, client: OpenAI):
        self.memory = Memory()
        self.planner = Planner(client)
        self.executor = Executor()

        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åˆæœŸåŒ–
        self.memory.add_message(
            "system",
            "ã‚ãªãŸã¯ADKæ§‹é€ ã§å®Ÿè£…ã•ã‚ŒãŸè¨ˆç®—ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚Planner/Executor/Memoryã®è²¬å‹™åˆ†é›¢ã‚’æ„è­˜ã—ã¦å‹•ä½œã—ã¾ã™ã€‚ãƒ„ãƒ¼ãƒ«ã‹ã‚‰è¿”ã•ã‚ŒãŸçµæœï¼ˆğŸš€ã‚’å«ã‚€ï¼‰ã¯ãã®ã¾ã¾æœ€çµ‚å›ç­”ã«å«ã‚ã¦ãã ã•ã„ã€‚",
        )

    def run(self, user_input: str):
        print(f"User: {user_input}")
        self.memory.add_message("user", user_input)

        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ— (æœ€å¤§5å›)
        for i in range(5):
            print(f"--- Loop {i+1} ---")

            # 1. Planning
            response_message: object = self.planner.plan(self.memory)

            # LLMã®å›ç­”ã‚’ä¸€æ—¦ãƒ¡ãƒ¢ãƒªã«è¿½åŠ ï¼ˆtool_callsãŒå«ã¾ã‚Œã‚‹å ´åˆã‚‚å«ã‚€ï¼‰
            # OpenAI APIã®ä»•æ§˜ã«åˆã‚ã›ã¦è¾æ›¸å½¢å¼ã§ä¿å­˜
            self.memory.add_message(
                role=getattr(response_message, "role", "assistant"),
                content=getattr(response_message, "content", "") or "",
                tool_calls=(
                    [
                        t.model_dump()
                        for t in getattr(response_message, "tool_calls", [])
                    ]
                    if getattr(response_message, "tool_calls", None)
                    else None
                ),
            )

            # 2. Check if Tool Call is required
            tool_calls = getattr(response_message, "tool_calls", None)
            if not tool_calls:
                # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒãªã‘ã‚Œã°çµ‚äº†ï¼ˆFinal Answerï¼‰
                print(f"Agent: {getattr(response_message, 'content', '')}")
                break

            # 3. Execution
            for tool_call in tool_calls:
                result = self.executor.execute(tool_call)

                # 4. Memory update with a Tool result
                self.memory.add_message(
                    role="tool",
                    content=result,
                    tool_call_id=getattr(tool_call, "id", None),
                    name=getattr(getattr(tool_call, "function", None), "name", None),
                )
        else:
            print("Error: Maximum loop count reached.")


if __name__ == "__main__":
    if validate_openai_api_key():
        api_key = os.getenv("OPENAI_API_KEY")
        openai_client = OpenAI(api_key=api_key)
        agent = Agent(openai_client)
        agent.run("3 + 5 ã‚’è¨ˆç®—ã—ã¦")
